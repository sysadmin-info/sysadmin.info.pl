---
title: Jak zainstalowa n8n w Kubernetes - k3s
date: 2023-12-29T11:00:00+00:00
description: Jak zainstalowa n8n w Kubernetes - k3s
draft: false
hideToc: false
enableToc: true
enableTocContent: false
author: sysadmin
authorEmoji: 
pinned: false
asciinema: true
series:
- Kubernetes
categories:
- Home Assistant
cover:
    image: images/2023-thumbs/ulanzi09.webp
---

{{<youtube gE4O2c1H8Vw>}}

##### Jak zainstalowa n8n w Kubernetes - k3s 

Szybka implementacja:

1. Zainstaluj git

```bash
sudo apt install git
```

2. Sklonuj repozytorium

```bash
git clone https://github.com/sysadmin-info/n8n-k3s.git
```

3. Wejd藕 do katalogu

```bash
cd n8n-k3s
```

4. Zainstaluj n8n w k3s

```bash
kubectl apply -f .
```

---

Szczeg贸y artykuu dotycz ustawienia n8n, narzdzia do automatyzacji przepywu pracy, na Kubernetes. Skupia si na u偶yciu plik贸w YAML do wdro偶enia Kubernetes.

**Kluczowe punkty:**

1. **Przegld n8n**: n8n to narzdzie do automatyzacji przepywu pracy w modelu fair-code, podobne do Zapierlub IFTTT, odpowiednie do samo-hostingu lub u偶ywania patnej usugi n8n.cloud.

2. **Konfiguracja Kubernetes dla n8n**:
   - **Tworzenie Namespace**: Pocztkowo, tworzona jest przestrze nazw Kubernetes 'n8n' za pomoc `kubectl create namespace n8n`.
   - **Konfiguracja Wdro偶enia i Usugi**:
     - `n8n-deployment.yaml`: Definiuje wdro偶enie z jedn replik kontenera n8n, eksponujc port 5678. Zawiera sondy gotowoci i zdolnoci dziaania na `/healthz`, zmienne rodowiskowe z ConfigMap (`n8n-configmap`) i Secret (`n8n-secrets`), oraz limity zasob贸w.
     - `n8n-service.yaml`: Ustawia usug NodePort dla n8n, mapujc port 80 na port kontenera 5678.

3. **StatefulSet PostgreSQL**:
   - `postgres-statefulset.yaml` i `postgres-service.yaml`: Definiuj StatefulSet i usug dla PostgreSQL, eksponujc port 5432, i powizane z Secret (`postgres-secrets`).

4. **ConfigMaps i Secrets**:
   - `n8n-configmap.yaml`: Zawiera zmienne rodowiskowe takie jak NODE_ENV, konfiguracje bazy danych i ustawienia webhook.
   - `n8n-secrets.yaml`: Zawiera sekrety dla n8n, w tym haso do bazy danych i klucz szyfrowania.
   - `postgres-secrets.yaml`: Przechowuje dane konfiguracyjne PostgreSQL.

5. **Proces Wdro偶enia**:
   - Stosowanie plik贸w konfiguracyjnych (`kubectl apply -f`) dla n8n i PostgreSQL.
   - U偶ywanie `kubectl rollout restart` do ponownego uruchomienia StatefulSet i Wdro偶enia po zastosowaniu konfiguracji.
   - Ostateczna konfiguracja obejmuje sprawdzanie usug (`kubectl get svc -n n8n`) i dostp do n8n za pomoc przegldarki, korzystajc z NodePort lub niestandardowej domeny przez NGINX Proxy Manager.

Artyku podkrela znaczenie dopasowania etykiet w konfiguracjach Kubernetes i zapewnia kompleksowy przewodnik po ustawieniu n8n z PostgreSQL na Kubernetes, wykorzystujc ConfigMaps i Secrets do zarzdzania konfiguracj.

---

### TLDR
Dla tych, kt贸rzy chcieliby przeczyta i dowiedzie si wicej, zobacz artyku:

#### Co to jest n8n{#what-is-n8n}

W skr贸cie, n8n to rozwizanie do automatyzacji przepywu pracy oparte na modelu dystrybucji fair-code, kt贸re jest darmowe i rozszerzalne. Jeli znasz rozwizania low-code/no-code takie jak [Zapier](https://zapier.com/) czy [IFTTT](https://ifttt.com/), n8n mo偶e by obsugiwane niezale偶nie i jest do nich podobne.

Bycie fair-code oznacza, 偶e zawsze masz prawo u偶ywa i rozpowszechnia kod 藕r贸dowy. Jedynym minusem jest to, 偶e mo偶esz musie zapaci za licencj na korzystanie z n8n, jeli zarabiasz na nim pienidze. Istniej doskonae ilustracje, jak ta metoda r贸偶ni si od tradycyjnych projekt贸w "open-source" w tej dyskusji spoecznoci [temat](https://community.n8n.io/t/doubts-about-fair-code-license/2502).

Przepywy pracy s wykonywane za pomoc serwera webowego NodeJS. Zosta zao偶ony w [czerwcu 2019](https://github.com/n8n-io/n8n/commit/9cb9804eeec1576d935817ecda6bd345480b97fa) i ju偶 zgromadzi [+280 wz贸w](https://n8n.io/integrations) i [+500 przepyw贸w pracy](https://n8n.io/workflows/). Spoeczno jest r贸wnie偶 do dynamiczna; czsto zajmuje kilka dni, aby atka zostaa poczona i udostpniona, co jest niesamowite!

Oznacza to, 偶e samodzielne hostowanie n8n jest do proste. Ponadto istnieje [n8n.cloud](https://www.n8n.cloud/), hostowana wersja, kt贸ra jest patna i eliminuje konieczno martwienia si o skalowanie, bezpieczestwo lub konserwacj.

---

#### Dlaczego u偶ywa n8n, a nie Zapiera?

Dla mnie to wysoka cena. 

Chocia偶 Zapier jest fantastyczny i najprawdopodobniej zdolny do obsugi ka偶dego przypadku u偶ycia, kt贸ry na niego rzucisz, ostatecznie darmowy poziom staje si nieprzydatny. Mo偶na projektowa tylko bardzo proste procesy "dwuetapowe" i szybko osiga si limity "zap贸w". Tylko klienci, kt贸rzy dokonuj patnoci, maj dostp do bardziej skomplikowanych przepyw贸w.

Ponadto, nie jest on hostowany w "twoim rodowisku" (samodzielne hostowanie lub wdro偶enie lokalne), co mo偶e by problematyczne, jeli masz rygorystyczne zasady dotyczce dzielenia si danymi z zewntrznymi dostawcami, na przykad. Poniewa偶 Zapier jest gotowy dla przedsibiorstw, mo偶esz by pewien, 偶e otrzymasz wszystkie potrzebne funkcje i wyjtkowe wsparcie klienta .

Jeli nie przeszkadza Ci kontrolowanie wasnej instancji (skalowalno, trwao, dostpno itp.), to n8n bdzie dziaa r贸wnie dobrze jak ka偶dy z jego konkurent贸w, kt贸rzy nie s darmowi.

Jednak celem tego artykuu jest pokazanie, jak skonfigurowalimy n8n na naszym klastrze Kubernetes, a nie dyskusja na temat korzyci pyncych z korzystania z Zapierlub n8n.

---

#### Jak skonfigurowa n8n w Kubernetes

Zamiast zaczyna od zera z cakowicie now konfiguracj Kubernetes, bdziemy korzysta z przykad贸w podanych przez [@bacarini](https://community.n8n.io/u/bacarini), u偶ytkownika forum spoecznociowego n8n, kt贸ry zaoferowa swoj [konfiguracj](https://community.n8n.io/t/running-with-kubernetes/681/13).

Do konfiguracji mojego klastra lokalnie u偶ywam K3s. Jeli jest to Tw贸j pierwszy raz z nim, mo偶esz po prostu ledzi [seri o Kubernetes](https://sysadmin.info.pl/en/series/kubernetes/).

Po zainstalowaniu K3s u偶yj nastpujcego polecenia, aby wdro偶y n8n w klastrze:

Zaczniesz od konfiguracji wdro偶enia n8n i udostpnisz j za pomoc jego konfiguracji usugi.

Ale najpierw musisz utworzy przestrze nazw n8n:

```bash
kubectl create namespace n8n
```

Nastpnie utw贸rz poni偶sze pliki:

```yaml
# n8n-deployment.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: n8n-deployment
  namespace: n8n
  labels: &labels
    app: n8n
    component: deployment
spec:
  replicas: 1
  selector:
    matchLabels: *labels
  template:
    metadata:
      labels: *labels
    spec:
      containers:
      - name: n8n
        image: n8nio/n8n:latest
        imagePullPolicy: IfNotPresent
        ports:
        - name: http
          containerPort: 5678
        envFrom:
        - configMapRef:
            name: n8n-configmap
        - secretRef:
            name: n8n-secrets
        livenessProbe:
          httpGet:
            path: /healthz
            port: 5678
        readinessProbe:
          httpGet:
            path: /healthz
            port: 5678
        resources:
          limits:
            cpu: "1.0"
            memory: "1024Mi"
          requests:
            cpu: "0.5"
            memory: "512Mi"
```

```yaml
# n8n-service.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: n8n-service
  namespace: n8n
  labels:
    app: n8n
    component: service
spec:
  type: NodePort
  selector:
    app: n8n
    component: deployment
  ports:
  - protocol: TCP
    name: http
    port: 80
    targetPort: 5678
```

Te pliki YAML s kluczowe dla konfiguracji n8n w Kubernetes. `n8n-deployment.yaml` definiuje wdro偶enie aplikacji n8n, okrelajc replik, obraz kontenera, porty, zmienne rodowiskowe oraz sondy gotowoci i zdolnoci dziaania. `n8n-service.yaml` tworzy usug Kubernetes dla n8n, definiujc, jak aplikacja jest eksponowana na zewntrz klastra.

Wa偶ne rzeczy, o kt贸rych nale偶y pamita tutaj:
* Aby unikn kopiowania i wklejania tych samych etykiet wewntrz siebie, przydzieliem zmienn &labels w konfiguracji yaml (dotyczy to wikszoci moich ustawie).
* w moim pliku n8n-deployment.yaml, ustawiem port kontenera n8n na 5678, co odpowiada domylnemu portowi n8n. Poprzez przekierowanie ruchu z portu 80 (http) na targetPort kontenera, m贸j n8n-service.yaml eksponuje kontener na tym porcie.
* M贸j kontener n8n jest poczony zar贸wno z moimi plikami n8n-configmap.yaml, jak i n8n-secrets.yaml, chocia偶 wci偶 musz je stworzy. Zajm si tym teraz.
* Aby sprawdzi, czy usuga dziaa, n8n oferuje punkt kocowy /healthz. U偶ywam tego punktu kocowego do ustawienia Sond Gotowoci i Zdolnoci Dziaania dla mojego wdro偶enia.
* Na koniec optymalizuj zasoby mojego kontenera, aby wykorzystywa maksymalnie 1 CPU i 1 GB RAM na moim klastrze.

Zwr贸 szczeg贸ln uwag na wyb贸r n8n-service. Nie bdziemy mogli dotrze do naszego serwera n8n, jeli konfiguracja yaml w kontenerze n8n-deployment nie bdzie pasowa do tych samych etykiet.

Mo偶esz dowiedzie si wicej o selektorach i o tym, jak wdro偶enia dziaaj z nimi tutaj: [tworzenie wdro偶enia Kubernetes](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#creating-a-deployment)

Korzystajc z tych dw贸ch ukad贸w, bd mia zatem nastpujce:

```bash
kubectl apply -f n8n-deployment.yaml,n8n-service.yaml
deployment.apps/n8n-deployment created
service/n8n-service created
```

Jeli to sprawdzisz, mo偶esz zauwa偶y, 偶e pod ```kubectl get pods -n n8n``` jest obecnie w stanie "CreateContainerConfigError". Jest to wynik braku konfiguracji ConfigMap i Secrets. Szybko to naprawi.

#### PostgreSQL StatefulSet

Konfiguracja StatefulSet Postgres jest bardzo podobna do naszych poprzednich konfiguracji wdro偶enia i wyglda nastpujco:

```yaml
# postgres-statefulset.yaml
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-statefulset
  namespace: n8n
  labels: &labels
    app: postgres
    component: statefulset
spec:
  serviceName: postgres-statefulset
  replicas: 1
  selector:
    matchLabels: *labels
  template:
    metadata:
      labels: *labels
    spec:
      containers:
      - name: postgres
        image: postgres:10
        ports:
        - name: postgres
          containerPort: 5432
        envFrom:
        - secretRef:
            name: postgres-secrets
```

```yaml
# postgres-service.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: postgres-service
  namespace: n8n
  labels: &labels
    app: postgres
    component: service
spec:
  clusterIP: None
  selector:
    app: postgres
    component: statefulset
  ports:
  - name: postgres
    port: 5432
    targetPort: 5432
```
Jak mo偶esz zauwa偶y, g贸wne r贸偶nice to:

* Domylny port dla serwera PostgreSQL to 5432, kt贸ry jest portem, kt贸ry obecnie udostpniam w obu moich plikach postgres-statefulset.yaml i postgres-service.yaml.
* Podobnie jak w poprzedniej konfiguracji, zwr贸 szczeg贸ln uwag na selektor usugi, poniewa偶 musi on by zgodny z etykietami kontenera zestawu stanowego.

Korzystajc z obu konfiguracji K8S, nale偶y wykona poni偶sze komendy:

```bash
kubectl apply -f postgres-statefulset.yaml,postgres-service.yaml
statefulset.apps/postgres-statefulset created
service/postgres-service created
```

#### ConfigMaps i Secrets

Musz tylko zainicjowa wszystkie podstawowe konfiguracje PostgreSQL i n8n, aby poczy te elementy:

* Moje wdro偶enie n8n jest poczone z konfiguracj Secrets o nazwie "n8n-secrets" oraz z ConfigMap o nazwie "n8n-configmap";
* Statefulset Postgres jest po prostu poczony z konfiguracj Secrets o nazwie "postgres-secrets."

```yaml
# n8n-configmap.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: n8n-configmap
  namespace: n8n
  labels:
    app: n8n
    component: configmap
data:
  NODE_ENV: "production"
  GENERIC_TIMEZONE: "Europe/Lisbon"
  WEBHOOK_TUNNEL_URL: "https://your.domain.com/"  # well come back to this later
  # Database configurations
  DB_TYPE: "postgresdb"
  DB_POSTGRESDB_USER: "n8n"
  DB_POSTGRESDB_DATABASE: "n8n"
  DB_POSTGRESDB_HOST: "postgres-service"
  DB_POSTGRESDB_PORT: "5432"
  # Turn on basic auth
  N8N_BASIC_AUTH_ACTIVE: "true"
  N8N_BASIC_AUTH_USER: "n8n"
```

```yaml
# n8n-secrets.yaml
---
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: n8n-secrets
  namespace: n8n
  labels:
    app: n8n
    component: secrets
stringData:
  # Database password
  DB_POSTGRESDB_PASSWORD: "n8n"
  # Basic auth credentials
  N8N_BASIC_AUTH_PASSWORD: "n8n"
  # Encryption key to hash all data
  N8N_ENCRYPTION_KEY: "n8n"
```

```yaml
# postgres-secrets.yaml
---
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: postgres-secrets
  namespace: n8n
  labels:
    app: postgres
    component: secrets
stringData:
  PGDATA: "/var/lib/postgresql/data/pgdata"
  POSTGRES_USER: "n8n"
  POSTGRES_DB: "n8n"
  POSTGRES_PASSWORD: "n8n"
```

Wikszo tych konfiguracji to kopie i wklejki z [podrcznika n8n](https://docs.n8n.io/reference/configuration.html) lub przykadu udostpnionego przez [@bacarini](https://community.n8n.io/t/running-with-kubernetes/681/13), ale wszystkie one s bardzo powszechne. Kluczem jest, jak poprzednio:

* ```DB_POSTGRESDB_HOST``` w n8n-configmap. Dla mojej usugi PostgreSQL, konfiguracja yaml musi by zgodna z nazw usugi.
* Dodatkowo, rodowisko ```WEBHOOK_TUNNEL_URL``` musi by zaktualizowane. Bdzie to g贸wnie wykorzystywane do wywoywania webhook贸w, jednak nie bdzie dziaa, jeli adres URL hosta nie jest prawidowy.

FAQ n8n radzi u偶ywa [ngrok do ustawienia tego URL](https://docs.n8n.io/credentials/twist/#how-to-configure-the-oauth-credentials-for-the-local-environment), ale odkryem, 偶e w k3s bdzie to funkcjonowa bez koniecznoci instalowania jakichkolwiek dodatkowych usug w systemie. Bd po prostu u偶ywa portu usugi, kt贸ry bdzie wywietlany przy u偶yciu poni偶szego polecenia:

```bash
kubectl get svc -n n8n
```

W moim rodowisku u偶ywam mened偶era proxy NGINX, w kt贸rym zdefiniowaem URL w spos贸b, jaki przedstawiem na filmie. Wic zamiast http://10.10.0.112:31600 u偶ywam n8n.local.

```yaml
# ~/k8s/n8n-configmap.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: n8n-configmap
  namespace: default
  labels:
    app: n8n
    component: configmap
data:
  WEBHOOK_TUNNEL_URL: "http://n8n.local/"
  (...)
```

Teraz mog po prostu zastosowa wszystkie trzy pliki konfiguracyjne, zrestartowa Statefulset i Deployment, a te konfiguracje zostan ponownie zaadowane:

```bash
kubectl apply -f kn8n-configmap.yaml,n8n-secrets.yaml,postgres-secrets.yaml
configmap/n8n-configmap created
secret/n8n-secrets created
secret/postgres-secrets created

$ kubectl rollout restart statefulset postgres-statefulset -n n8n
statefulset.apps/postgres-statefulset restarted

$ kubectl rollout restart deployment n8n-deployment -n n8n
deployment.apps/n8n-deployment restarted

$ kubectl get all -n n8n
NAME                                  READY   STATUS    RESTARTS       AGE
pod/n8n-deployment-5c97d55b5f-2tv5b   1/1     Running   55 (27h ago)   2d
pod/postgres-statefulset-0            1/1     Running   1 (27h ago)    28h

NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
service/n8n-service        NodePort    10.43.184.200   <none>        80:31600/TCP   2d22h
service/postgres-service   ClusterIP   None            <none>        5432/TCP       2d22h

NAME                             READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/n8n-deployment   1/1     1            1           2d22h

NAME                                        DESIRED   CURRENT   READY   AGE
replicaset.apps/n8n-deployment-84d7b5cd76   0         0         0       2d22h
replicaset.apps/n8n-deployment-65dfc7d567   0         0         0       2d22h
replicaset.apps/n8n-deployment-5c97d55b5f   1         1         1       2d22h

NAME                                    READY   AGE
statefulset.apps/postgres-statefulset   1/1     2d22h
```

#### Teraz wszystko razem 

Powiniene mie co podobnego w swoim katalogu roboczym, jeli zapisywae konfiguracje wymienione powy偶ej:

```bash
adrian@cm4:~ $ ls -lha n8n-deployment/
razem 36K
drwxr-xr-x  2 adrian adrian 4.0K 19 gru 15:46 .
drwxr-xr-x 12 adrian adrian 4.0K 21 gru 10:13 ..
-rw-r--r--  1 adrian adrian  509 19 gru 15:30 n8n-configmap.yaml
-rw-r--r--  1 adrian adrian  904 19 gru 15:29 n8n-deployment.yaml
-rw-r--r--  1 adrian adrian  328 19 gru 11:40 n8n-secrets.yaml
-rw-r--r--  1 adrian adrian  276 19 gru 11:38 n8n-service.yaml
-rw-r--r--  1 adrian adrian  275 19 gru 11:41 postgres-secrets.yaml
-rw-r--r--  1 adrian adrian  289 19 gru 11:39 postgres-service.yaml
-rw-r--r--  1 adrian adrian  523 19 gru 11:39 postgres-statefulset.yaml
```

Wszystkie konfiguracje mog by wdro偶one jednoczenie poprzez wykonanie:

```bash
kubectl apply -f.
```
Nadszed wreszcie czas, aby uruchomi nasz serwer n8n w przegldarce!

Wic, sprawd藕 serwis

```bash
kubectl get svc -n n8n
```

i adres IP maszyny, na kt贸rej dziaa K3s

```bash
hostname -I
```

i u偶yj NodePort, kt贸ry eksponuje usug.

Ostatecznie powinno to by np. http://10.10.0.112:31600 lub po prostu http://n8n.local, poniewa偶 u偶ywam wasnego serwera DNS (Adguard Home).