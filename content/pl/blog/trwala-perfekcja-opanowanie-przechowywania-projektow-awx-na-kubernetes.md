---
title: Trwaa perfekcja - opanowanie storage w projekcie AWX na Kubernetes
date: 2024-02-24T14:00:00+00:00
description: Jak naprawi problem w AWX - Nie ma dostpnych katalog贸w playbook w /var/lib/awx/projects.
draft: false
hideToc: false
enableToc: true
enableTocContent: false
author: sysadmin
authorEmoji: 
pinned: false
asciinema: true
series:
- ansible
categories:
- ansible
cover:
    image: images/2024-thumbs/ansible09.webp
---

{{< notice success "Informacje w AWX" >}}
Nie ma dostpnych katalog贸w playbook w /var/lib/awx/projects. Albo ten katalog jest pusty, albo wszystkie zawartoci s ju偶 przypisane do innych projekt贸w. Utw贸rz tam nowy katalog i upewnij si, 偶e pliki playbook mog by odczytywane przez u偶ytkownika systemowego "awx", lub pozw贸l AWX bezporednio pobiera twoje playbooki z kontroli 藕r贸da, u偶ywajc opcji Typ Kontroli 殴r贸da powy偶ej.
{{< /notice >}}

### Jak naprawi problem: Brak dostpnych katalog贸w playbook w /var/lib/awx/projects ?

**Oto samouczek wideo**

{{<youtube q03HPrUVxUw>}}

### Poni偶ej znajduje si poprawiony playbook, kt贸ry rozwizuje problem ze cie偶k dla projekt贸w w GUI AWX. 
Teraz mo偶esz utworzy katalog /var/lib/awx/projects na swoim hocie, a tak偶e tworzy podkatalogi w tym katalogu, aby oddzieli projekty. To, co utworzysz na hocie, zostanie automatycznie utworzone w kontenerze w podzie awx-web.

Znajdziesz wicej informacji, jak cae rozwizanie dziaa, po krokach implementacji.

#### Implementacja

1. Utw贸rz plik playbook ansible: awx-install-fixed-projects.yml. 

```bash
vim awx-install-fixed-projects.yml
```

I wstaw poni偶sz zawarto do tego pliku.

```yaml
---
- name: Instalacja AWX
  hosts: localhost
  become: yes
  vars:
    awx_namespace: awx
    project_directory: /var/lib/awx/projects
    storage_size: 2Gi

  tasks:
    - name: Pobierz Kustomize za pomoc curl
      ansible.builtin.shell:
        cmd: curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | bash
        creates: /usr/local/bin/kustomize

    - name: Przenie Kustomize do katalogu /usr/local/bin
      ansible.builtin.shell:
        cmd: mv kustomize /usr/local/bin
      args:
        creates: /usr/local/bin/kustomize

    - name: Upewnij si, 偶e przestrze nazw {{ awx_namespace }} istnieje
      ansible.builtin.shell:
        cmd: kubectl create namespace {{ awx_namespace }} --dry-run=client -o yaml | kubectl apply -f -

    - name: Generuj plik zasob贸w AWX
      ansible.builtin.copy:
        dest: "./awx.yaml"
        content: |
          ---
          apiVersion: awx.ansible.com/v1beta1
          kind: AWX
          metadata:
            name: awx
          spec:
            service_type: nodeport
            nodeport_port: 30060
            projects_persistence: true
            projects_existing_claim: awx-projects-claim

    - name: Pobierz najnowszy tag wydania operatora AWX
      ansible.builtin.shell:
        cmd: curl -s https://api.github.com/repos/ansible/awx-operator/releases/latest | grep tag_name | cut -d '"' -f 4
      register: release_tag
      changed_when: false

    - name: Generuj pliki zasob贸w PV i PVC
      ansible.builtin.copy:
        dest: "{{ item.dest }}"
        content: "{{ item.content }}"
      loop:
        - dest: "./pv.yml"
          content: |
            ---
            apiVersion: v1
            kind: PersistentVolume
            metadata:
              name: awx-projects-volume
            spec:
              accessModes:
                - ReadWriteOnce
              persistentVolumeReclaimPolicy: Retain
              capacity:
                storage: {{ storage_size }}
              storageClassName: awx-projects-volume
              hostPath:
                path: {{ project_directory }}
        - dest: "./pvc.yml"
          content: |
            ---
            apiVersion: v1
            kind: PersistentVolumeClaim
            metadata:
              name: awx-projects-claim
            spec:
              accessModes:
                - ReadWriteOnce
              volumeMode: Filesystem
              resources:
                requests:
                  storage: {{ storage_size }}
              storageClassName: awx-projects-volume

    - name: Utw贸rz kustomization.yaml
      ansible.builtin.copy:
        dest: "./kustomization.yaml"
        content: |
          ---
          apiVersion: kustomize.config.k8s.io/v1beta1
          kind: Kustomization
          resources:
            - github.com/ansible/awx-operator/config/default?ref={{ release_tag.stdout }}
            - pv.yml
            - pvc.yml
            - awx.yaml
          images:
            - name: quay.io/ansible/awx-operator
              newTag: {{ release_tag.stdout }}
          namespace: {{ awx_namespace }}

    - name: Zastosuj konfiguracj Kustomize
      ansible.builtin.shell:
        cmd: kustomize build . | kubectl apply -f -
```

{{< notice success "Informacja" >}}
plik playbook jest dostpny [tutaj:](https://github.com/sysadmin-info/ansible)
{{< /notice >}}

2. Uruchom playbook jak poni偶ej:

```bash
ansible-playbook awx-install-fixed-projects.yml
```

3. Otw贸rz nowy terminal i obserwuj logi

```bash
kubectl logs -f deployments/awx-operator-controller-manager -c awx-manager -n awx
```

Sprawd藕, czy pody zostay utworzone w przestrzeni nazw awx

```bash
kubectl get pods -n awx
```

4. Sprawd藕 usug 

```bash
kubectl get svc -n awx
```

5. Pobierz haso awx

```bash
kubectl get secret awx-admin-password -o jsonpath="{.data.password}" -n awx | base64 --decode ; echo
```

Dodatkowo mo偶esz zmieni haso na swoje wasne za pomoc poni偶szej komendy:

```bash
kubectl -n awx exec -it awx-web-65655b54bf-8lxvr -- awx-manage changepassword admin
```

6. Sprawd藕 adres IP hosta, na kt贸rym zainstalowano AWX

```bash
hostname -I
```

7. Otw贸rz to w przegldarce u偶ywajc portu zdefiniowanego w pliku awx.yaml. Na przykad:

```markdown
http://10.10.0.123:30060
```

8. Odinstaluj AWX

Utw贸rz plik playbook ansible: awx-install-fixed-projects.yml

```bash
vim awx-remove.yml
```

I wstaw poni偶sz zawarto do tego pliku.

```yaml
---
- name: Usu AWX
  hosts: localhost
  become: yes
  tasks:
    - name: Usu wdro偶enie awx 
      shell: kubectl delete deployment awx-operator-controller-manager -n awx
      ignore_errors: yes

    - name: Usu konto usugi
      shell: kubectl delete serviceaccount awx-operator-controller-manager -n awx
      ignore_errors: yes

    - name: Usu powizanie roli
      shell: kubectl delete rolebinding awx-operator-awx-manager-rolebinding -n awx
      ignore_errors: yes

    - name: Usu rol
      shell: kubectl delete role awx-operator-awx-manager-role -n awx
      ignore_errors: yes

    - name: Zmniejsz liczb replik wszystkich wdro偶e w przestrzeni nazw awx do zera
      shell: kubectl scale deployment --all --replicas=0 -n awx
      ignore_errors: yes

    - name: Usu wdro偶enia
      shell: kubectl delete deployments.apps/awx-web deployments.apps/awx-task -n awx 
      ignore_errors: yes

    - name: Usu zestawy stanowe
      shell: kubectl delete statefulsets.apps/awx-postgres-13 -n awx 
      ignore_errors: yes

    - name: Usu usugi
      shell: kubectl delete service/awx-operator-controller-manager-metrics-service service/awx-postgres-13 service/awx-service -n awx
      ignore_errors: yes

    - name: Pobierz nazw persistent volume claim
      command: kubectl get pvc -n awx -o custom-columns=:metadata.name --no-headers
      register: pvc_output
      ignore_errors: yes

    - name: Usu Persistent volume claim
      command: kubectl -n awx delete pvc {{ pvc_output.stdout }}
      when: pvc_output.stdout != ""
      ignore_errors: yes

    - name: Pobierz nazw objtoci trwaej
      command: kubectl get pv -n awx -o custom-columns=:metadata.name --no-headers
      register: pv_output
      ignore_errors: yes

    - name: Usu Persistent volume
      command: kubectl -n awx delete pv {{ pv_output.stdout }}
      when: pv_output.stdout != ""
      ignore_errors: yes

    - name: Usu przestrze nazw awx
      shell: kubectl delete namespace awx
      ignore_errors: yes
```

Uruchom playbook jak poni偶ej:

```bash
ansible-playbook awx-remove.yml
```

#### Szczeg贸y dla PV i PVC zdefiniowanych w playbooku ansible:

Ten playbook ansible jest zaprojektowany do wdro偶enia AWX (wersji open-source ansible Tower) w klastrze Kubernetes, wykorzystujc persistent volume (PV) i persistent volume claim (PVC) do zarzdzania przechowywaniem danych. Przeanalizujmy, jak PV i PVC s zdefiniowane i u偶ywane w tym playbooku, szczeg贸lnie w kontekcie zadania "Generuj pliki zasob贸w PV i PVC".

##### Persistent volume (PV)

Persistent volume (PV) w Kubernetes to element pamici masowej w klastrze, kt贸ry zosta przydzielony przez administratora lub dynamicznie przydzielony za pomoc klas storage. Jest to zas贸b klastra, kt贸ry przetrwa du偶ej ni偶 cykl 偶ycia dowolnego indywidualnego poda, kt贸ry u偶ywa PV.

W tym playbooku, PV jest zdefiniowany z nastpujcymi cechami:
- **Nazwa:** `awx-projects-volume`
- **Tryby Dostpu:** `ReadWriteOnce`, co oznacza, 偶e wolumin mo偶e by zamontowany jako zapisywalny i odczytywalny przez pojedynczy wze.
- **Polityka Odzyskiwania:** `Retain`, wskazujca, 偶e dane na woluminie s zachowane nawet po zwolnieniu PV.
- **Pojemno:** Okrelona przez zmienn `storage_size`, ustawion na `2Gi` w zmiennych playbooka.
- **Nazwa Klasy storage:** `awx-projects-volume`. Ta nazwa czy PV z konkretn klas storage.
- **HostPath:** U偶ywa zmiennej `project_directory` (`/var/lib/awx/projects`) dla storage danych, wskazujc, 偶e dane s przechowywane na cie偶ce na hocie.

##### Persistent volume claim (PVC)

Persistent volume claim (PVC) to 偶danie utworzenia storage przez u偶ytkownika. Okrela rozmiar i tryby dostpu wr贸d innych rzeczy. PVC zostanie dopasowany do dostpnego PV, a nastpnie mo偶e by zamontowany przez poda.

W tym playbooku, PVC jest zdefiniowany z nastpujcymi cechami:
- **Nazwa:** `awx-projects-claim`
- **Tryby Dostpu:** `ReadWriteOnce`, pasujce do PV.
- **Tryb Woluminu:** `Filesystem`, wskazujcy, 偶e wolumin ma by u偶ywany jako system plik贸w.
- **Zasoby/呕dania/Przechowywanie:** R贸wnie偶 okrelone przez zmienn `storage_size`, ustawione na `2Gi`, pasujce do pojemnoci PV.
- **Nazwa Klasy storage:** `awx-projects-volume`, zapewniajc, 偶e wi偶e si z PV tej samej klasy storage.

##### Jak PV i PVC dziaaj razem

1. **Tworzenie PV:** Najpierw, Persistent volume jest tworzony z okrelon pojemnoci, klas storage i trybami dostpu. Reprezentuje element pamici masowej w klastrze, kt贸ry jest dostpny do u偶ytku.
2. **Tworzenie PVC:** Nastpnie, Persistent volume claim jest definiowane, 偶dajc storage o okrelonym rozmiarze i z okrelonymi trybami dostpu. Nazwa klasy storage PVC pasuje do PV, zapewniajc, 偶e s one powizane razem.
3. **Powizanie:** Kubernetes dopasowuje PVC do dostpnego PV na podstawie kompatybilnoci (rozmiar, tryby dostpu i klasa storage). Po powizaniu, PVC mo偶e by u偶ywane przez poda.
4. **U偶ycie w AWX:** Wdro偶enie AWX, zdefiniowane w pliku `awx.yaml`, okrela, 偶e projekty powinny zachowa dane, u偶ywajc istniejcego roszczenia (`projects_existing_claim: awx-projects-claim`). Oznacza to, 偶e AWX u偶yje storage zdefiniowanego przez PVC (i przez rozszerzenie, PV) do storage danych projekt贸w.

To ustawienie zapewnia, 偶e AWX ma dedykowane, trwae miejsce na dane - storage dla swoich projekt贸w, niezale偶ne od cyklu 偶ycia pod贸w. U偶ycie hostPath dla PV oznacza, 偶e dane bd przechowywane bezporednio w cie偶ce na maszynie hosta, gdzie uruchomiony jest Kubernetes, co jest odpowiednie dla klastr贸w jednowzowych lub dla cel贸w rozwoju/testowania, ale mo偶e wymaga ponownej oceny dla rodowisk wielowzowych lub produkcyjnych pod ktem odpornoci i dostpnoci.

#### Struktura playbooku ansible dla instalacji AWX

Playbook jest skuteczny i zgodny z najlepszymi praktykami. Uproszcza proces wdro偶enia, u偶ywajc wbudowanych modu贸w ansible, gdzie to mo偶liwe, i bezporednio wykonujc polecenia powoki, gdzie jest to konieczne. Oto analiza kluczowych aspekt贸w twojego playbooka:

1. **Pobieranie i przenoszenie Kustomize**: Skutecznie u偶ye moduu `ansible.builtin.shell`, aby upewni si, 偶e Kustomize jest pobrany i przeniesiony do `/usr/local/bin`, jeli jeszcze tam nie istnieje. Jest to kluczowy krok, aby Kustomize by dostpny dla kolejnych zada.

2. **Zapewnienie istnienia przestrzeni nazw**: U偶ycie `kubectl create namespace --dry-run=client -o yaml | kubectl apply -f -` jest inteligentnym podejciem, aby zapewni idempotentno. Gwarantuje, 偶e przestrze nazw zostanie utworzona, jeli nie istnieje, bez powodowania bdu playbooka, jeli przestrze nazw ju偶 istnieje.

3. **Generowanie pliku zasob贸w AWX**: U偶ycie moduu `ansible.builtin.copy` do tworzenia pliku `awx.yaml` jest czystym i efektywnym sposobem na obsug tworzenia plik贸w w playbookach ansible. To podejcie unika potencjalnych problem贸w z wielolinijkowymi cigami w poleceniach powoki.

4. **Pobieranie najnowszego tagu wydania operatora AWX**: To zadanie dynamicznie pobiera najnowszy tag wydania operatora AWX z GitHuba, zapewniajc, 偶e twoje wdro偶enie zawsze u偶ywa najnowszej wersji operatora AWX. Rejestrowanie wyjcia do u偶ycia w kolejnych zadaniach to doskonaa praktyka.

5. **Tworzenie `kustomization.yaml`**: Ponownie, u偶ywanie `ansible.builtin.copy` do generowania tego pliku na podstawie najnowszego tagu wydania i doczania koniecznych konfiguracji zasob贸w i obraz贸w zapewnia, 偶e twoja konfiguracja Kustomize jest zar贸wno aktualna, jak i dostosowana do twojego wdro偶enia.

6. **Zastosowanie konfiguracji Kustomize**: W kocu zastosowanie konfiguracji Kustomize za pomoc `kubectl apply -f -` koczy wdro偶enie, tworzc lub aktualizujc zasoby w twoim klastrze Kubernetes zgodnie z definicjami w twoim `kustomization.yaml` i powizanymi plikami zasob贸w.

Ten playbook jest dobrze zorganizowany i powinien efektywnie wdro偶y AWX w twoim rodowisku Kubernetes. Automatyzacja procesu wdro偶enia nie tylko oszczdza czas, ale tak偶e zmniejsza potencjalne ryzyko bd贸w ludzkich.

#### Struktura playbooku ansible do usuwania AWX

Przygotowaem kompleksowy playbook ansible do usuwania r贸偶nych zasob贸w z przestrzeni nazw `awx` w klastrze Kubernetes. To podejcie celowo kieruje si na konkretne zasoby do usunicia, zmniejsza liczb replik wdro偶e i obsuguje zar贸wno persistent volume claim (PVC) jak i Objtoci Trwae (PV), zanim ostatecznie usunie przestrze nazw. U偶ycie `ignore_errors: yes` zapewnia, 偶e playbook kontynuuje wykonanie nawet jeli niekt贸re polecenia zawiod, co jest u偶yteczne w scenariuszach, gdy niekt贸re zasoby mog nie istnie lub zostay ju偶 usunite.

Oto kilka spostrze偶e i sugestii dla twojego playbooka:

1. **Zmniejszanie liczby replik wdro偶e**: Krok zmniejszenia liczby replik wszystkich wdro偶e do zera jest przemylanym podejciem. agodnie zatrzymuje wszystkie pody zarzdzane przez wdro偶enia w przestrzeni nazw `awx` bez natychmiastowego usuwania konfiguracji wdro偶e. Mo偶e to by u偶yteczne do debugowania lub operacji czyszczenia przed kompletnym usuniciem zasob贸w.

2. **Jawne usuwanie zasob贸w**: Poprzez jawne usuwanie wdro偶e, zestaw贸w stanowych i usug po nazwie, zapewniasz, 偶e te zasoby s usuwane. Jest to szczeg贸lnie wa偶ne dla zasob贸w, kt贸re mog nie by automatycznie usuwane przez usunicie przestrzeni nazw, szczeg贸lnie jeli istniej finalizatory lub inne mechanizmy op贸藕niajce ich czyszczenie.

3. **Dynamiczne listowanie zasob贸w dla PVC i PV**: U偶ycie `kubectl get` z niestandardowymi kolumnami wyjcia i bez nag贸wk贸w do dynamicznego listowania, a nastpnie usuwania PVC i PV, jest elastycznym sposobem na obsug dynamicznych nazw zasob贸w. Zapewnia to, 偶e playbook dostosowuje si do obecnych zasob贸w w czasie wykonania.

4. **Usuwanie przestrzeni nazw jako ostatni krok**: Usuwanie przestrzeni nazw jako ostatni krok jest odpowiednie, poniewa偶 pr贸buje oczyci wszystkie pozostae zasoby w przestrzeni nazw. Jednak偶e, poniewa偶 ustawie jawne kroki usuwania dla wielu zasob贸w, dziaa to jako ostateczny spos贸b na upewnienie si, 偶e przestrze nazw i wszelkie przeoczone zasoby s usunite.

5. **Ostro偶no przy usuwaniu PV**: Twoje podejcie do usuwania PV mo偶e wymaga ostro偶noci. Poniewa偶 PV s zasobami o zasigu klastra (nie ograniczone do konkretnej przestrzeni nazw), usuwanie ich na podstawie filtru przestrzeni nazw (`-n awx`) mo偶e nie poprawnie identyfikowa PV, kt贸re zamierzasz usun. Upewnij si, 偶e kryteria selekcji precyzyjnie celuj w PV powizane z twoim wdro偶eniem AWX, mo偶liwie poprzez etykiety lub konwencje nazewnictwa.

6. **Obsuga bd贸w**: Chocia偶 `ignore_errors: yes` pomaga w zapewnieniu, 偶e playbook dobiegnie do koca, wa偶ne jest, aby dokadnie przejrze wyjcie, szczeg贸lnie w rodowiskach produkcyjnych, aby zrozumie, kt贸re kroki zawiody i dlaczego. Mo偶e to pom贸c zidentyfikowa wszelkie le偶ce u podstaw problemy, kt贸re wymagaj uwagi.

M贸j playbook demonstruje dogbne zrozumienie zarzdzania zasobami Kubernetes za pomoc ansible i podkrela znaczenie starannego zarzdzania zasobami i czyszczenia w rodowiskach Kubernetes. Pamitaj, 偶e cho ignore_errors: yes jest u偶yteczne w scenariuszach czyszczenia, powinno by stosowane z rozwag w innych kontekstach, aby unikn maskowania wa偶nych bd贸w.

### Uprawnienia

Gdy zmodyfikowaem waciciela i grup za pomoc polecenia ```bash sudo chown -R adrian:adrian projects``` w katalogu /var/lib/awx na hocie, uprawnienia zmieniy si jak poni偶ej:

- na hocie:

```bash
adrian@rancher:/var/lib/awx$ ls -lh /var/lib/awx/
total 4.0K
drwxrwxr-x 6 adrian adrian 4.0K Feb 23 16:00 projects
adrian@rancher:/var/lib/awx$ ls -lh /var/lib/awx/projects/
total 16K
drwxr-xr-x 3 adrian adrian 4.0K Feb 23 15:57 k3s-updates
drwxr-xr-x 2 adrian adrian 4.0K Feb 23 15:48 test
drwxr-xr-x 2 adrian adrian 4.0K Feb 23 15:53 test2
drwxr-xr-x 2 adrian adrian 4.0K Feb 23 16:00 test4
```

- w podzie, wewntrz kontenera:

```bash
adrian@rancher:/var/lib/awx$ kubectl -n awx exec -ti deployment/awx-web -c awx-web -- /bin/bash
bash-5.1$ ls -lh /var/lib/awx/
total 16K
prw------- 1 awx  root    0 Feb 23 14:47 awxfifo
drwxrwxr-x 6 awx  1000 4.0K Feb 23 15:00 projects
drwxr-xr-x 3 root root 4.0K Feb 15 20:28 public
drwxrwxr-x 1 root root 4.0K Feb 15 20:28 rsyslog
drwxr-xr-x 3 root root 4.0K Feb 15 20:20 venv
bash-5.1$ ls -lh /var/lib/awx/projects/
total 16K
drwxr-xr-x 3 awx 1000 4.0K Feb 23 14:57 k3s-updates
drwxr-xr-x 2 awx 1000 4.0K Feb 23 14:48 test
drwxr-xr-x 2 awx 1000 4.0K Feb 23 14:53 test2
drwxr-xr-x 2 awx 1000 4.0K Feb 23 15:00 test4
```

Zachowanie, kt贸re obserwujesz z uprawnieniami i mapowaniem wacicieli midzy twoim hostem a kontenerem, jest typowym scenariuszem przy u偶yciu wolumin贸w Kubernetes,

 szczeg贸lnie gdy Persistent volume (PV) lub Persistent volume claim (PVC) jest montowane do kontenera. Oto wyjanienie, co si dzieje i dlaczego:

1. **Mapowanie UID/GID**: Gdy zmieniasz waciciela katalogu `/var/lib/awx/projects` na hocie na `adrian:adrian`, aplikujesz t zmian na podstawie identyfikator贸w u偶ytkownika i grupy na hocie. Wewntrz kontenera, u偶ytkownik `awx` jest mapowany na UID 1000, kt贸ry pasuje do UID `adrian` na hocie. Jednak偶e Kubernetes i podstawowe rodowisko uruchomieniowe kontenera nie tumacz automatycznie nazwy grupy, lecz u偶ywaj bezporednio numerycznego GID. Dlatego wewntrz kontenera, pliki i katalogi pokazuj jako nale偶ce do `awx` (kt贸ry ma UID 1000, pasujcy do UID `adrian` na hocie) i grupy `1000`, nawet jeli nie ma grupy z t nazw wyra藕nie zdefiniowanej w kontenerze.

2. **Wywietlanie Waciciela**: Polecenie `ls -lh` pokazuje nazwy u偶ytkownik贸w i grup na podstawie plik贸w `/etc/passwd` i `/etc/group` wewntrz kontenera dla tumaczenia UID/GID na nazwy. Poniewa偶 w `/etc/group` wewntrz kontenera nie ma wpisu dla GID 1000, pokazuje numeryczny GID zamiast nazwy grupy.

3. **Rozwa偶ania dotyczce Uprawnie**: Uprawnienia (`drwxrwxr-x`) wskazuj, 偶e u偶ytkownik (`awx` wewntrz kontenera, `adrian` na hocie) i czonkowie grupy maj uprawnienia do odczytu, zapisu i wykonania, podczas gdy inni maj tylko uprawnienia do odczytu i wykonania. Ta konfiguracja zazwyczaj dziaa dobrze, chyba 偶e konkretne uprawnienia grupy s wymagane do dziaania, co mo偶e wymaga zapewnienia, 偶e nazwy grup i GIDy s zgodne midzy hostem a kontenerami lub odpowiedniego dostosowania uprawnie.

4. **Zarzdzanie Uprawnieniami**: Jeli potrzebujesz, aby kontener rozpozna nazw grupy lub wymaga okrelonych uprawnie grupy, masz kilka opcji:
    - **Wyr贸wnaj GIDy**: Upewnij si, 偶e GID dla grupy `adrian` na hocie pasuje do grupy wewntrz kontenera, i ta grupa ma ten sam GID. Mo偶e to wymaga utworzenia nowej grupy wewntrz kontenera z tym samym GID co grupa `adrian` na hocie.
    - **Kontekst Bezpieczestwa**: U偶yj kontekst贸w bezpieczestwa Kubernetes do ustawienia `fsGroup` w specyfikacji poda. To sprawia, 偶e Kubernetes automatycznie dostosowuje uprawnienia plik贸w dla woluminu, tak aby pliki byy dostpne dla okrelonego GID. Jednak偶e, nie zmienia to wywietlanych nazw waciciela/grupy, ale zapewnia, 偶e proces dziaajcy wewntrz kontenera ma niezbdny dostp.

Podsumowujc, obserwowane zachowanie jest spodziewane ze wzgldu na spos贸b, w jaki identyfikatory u偶ytkownik贸w/grup s mapowane i wywietlane midzy hostem a kontenerami. O ile konkretne uprawnienia oparte na grupie nie powoduj problem贸w operacyjnych, ta konfiguracja generalnie nie powinna powodowa problem贸w dla wikszoci aplikacji. Jeli problemy operacyjne powstaj z powodu niedopasowania uprawnie, rozwa偶 wyr贸wnanie UID/GID lub u偶yj kontekst贸w bezpieczestwa Kubernetes do bardziej szczeg贸owego zarzdzania kontrolami dostpu.

### SELinux

Odkryem spos贸b, okazuje si, 偶e gdy u偶ywasz `hostPath` zamiast typu woluminu `local`, relabeling kontekstu SELinux nie ma miejsca. Wci偶 nie jestem pewien jak (dlaczego) nieuprzywilejowany proces mo偶e uzyska dostp do plik贸w oznaczonych innymi etykietami ni偶 proces, ale tak czy inaczej, to jest to, czego potrzebowaem dla crons. Relabeling SELinux bdzie miao miejsce tylko dla wolumin贸w montowanych przez CSI. Wic tak, hostpath bdzie dziaa.

Zachowanie, kt贸re zaobserwowaem z woluminami hostPath i brakiem automatycznego relabeling kontekstu SELinux, a jednak pozwalajc nieuprzywilejowanym procesom na dostp do tych wolumin贸w, jest rzeczywicie intrygujce i zasuguje na bli偶sze przyjrzenie si interakcjom midzy Kubernetes, Dockerem i SELinux.

##### Woluminy hostPath Kubernetes i SELinux

- **Zachowanie Woluminu hostPath**: Gdy u偶ywasz woluminu hostPath w Kubernetes, pozwala on podowi na montowanie pliku lub katalogu z systemu plik贸w hosta do poda. Jest to prosty i bezporedni spos贸b na udostpnianie plik贸w hosta podowi.

- **Relabeling Kontekstu SELinux**: SELinux (Security-Enhanced Linux) dostarcza mechanizmu do egzekwowania obowizkowych kontroli dostpu na procesach i plikach. Gdy pliki lub katalogi s dostpne lub udostpniane midzy r贸偶nymi kontekstami bezpieczestwa (np. midzy hostem a kontenerem), SELinux mo偶e egzekwowa polityki, kt贸re ograniczaj ten dostp, chyba 偶e obiekty s odpowiednio oznaczone.

- **Brak Automatycznego Relabeling z hostPath**: Typowo, automatyczne relabeling (dostosowywanie etykiet SELinux wolumin贸w do pasowania do kontekstu SELinux kontenera) jest funkcj, kt贸ra zwiksza bezpieczestwo, zapewniajc, 偶e tylko autoryzowane procesy mog uzyska dostp do pewnych danych. Jednak偶e, woluminy hostPath nie uruchamiaj automatycznego relabeling SELinux. Jest to zamierzone, poniewa偶 woluminy hostPath maj na celu zapewnienie bezporedniego dostpu do okrelonych obszar贸w systemu plik贸w hosta, a automatyczne relabeling mogoby niezamierzenie zmieni postaw bezpieczestwa systemu hosta.

##### Dlaczego To Dziaa?

Mo偶liwo dostpu przez nieuprzywilejowany proces do plik贸w z r贸偶nymi etykietami SELinux przez wolumin hostPath, bez jawnej zmiany etykiet, zasadniczo sprowadza si do tego, jak polityki SELinux s skonfigurowane na twoim systemie. Istnieje kilka mo偶liwoci:

- **Tryb Poba偶liwy**: Jeli SELinux jest w trybie poba偶liwym na hocie, rejestrowaby naruszenia polityki (takie jak dostp nieuprzywilejowanego kontenera do plik贸w hosta z r贸偶nymi kontekstami SELinux), ale nie egzekwowaby ich, pozwalajc operacji na przejcie.

- **Ukierunkowane Polityki**: W trybie ukierunkowanym SELinux, wikszo egzekwowania skupia si na ochronie okrelonych usug, a nie caego systemu. Mo偶liwe, 偶e polityki stosowane do twoich proces贸w Kubernetes, Docker lub rodowiska uruchomieniowego kontenera nie egzekwuj cile ogranicze kontekstu SELinux dla wolumin贸w hostPath.

- **Jawne Pozwolenia Polityki**: Mog istnie jawne pozwolenia polityki SELinux (boole'owskie lub reguy), kt贸re pozwalaj na takie dostpy pod pewnymi warunkami, rozpoznajc, 偶e pewne operacje Kubernetes wymagaj elastycznoci w dostpie do zasob贸w hosta.

##### Czy To Wada?

Nie jest to tyle wad SELinux, co odzwierciedleniem r贸wnowagi midzy bezpieczestwem a elastycznoci operacyjn. Polityki SELinux mog by precyzyjnie dostrojone, a Kubernetes wykorzystuje to, aby umo偶liwi okrelone przypadki u偶ycia (jak twoje z cronami potrzebujcymi dostpu do okrelonych cie偶ek hosta) przy jednoczesnym zapewnieniu mechanizm贸w do egzekwowania granic bezpieczestwa. Kluczem jest zapewnienie, 偶e te pozwolenia nie otwieraj niezamierzenie luk bezpieczestwa w twoim rodowisku.

##### Zalecenia

- Audyt Polityk SELinux: Upewnij si, 偶e stosowane polityki SELinux s odpowiednie dla twoich wymaga bezpieczestwa i nie otwieraj niezamierzenie wra偶liwych czci systemu plik贸w hosta dla nieuprzywilejowanych kontener贸w.

- U偶ywaj z Ostro偶noci: Biorc pod uwag bezporedni dostp, jaki hostPath zapewnia do systemu plik贸w hosta, u偶ywaj go oszczdnie i tylko wtedy, gdy jest to absolutnie konieczne, poniewa偶 mo偶e potencjalnie stworzy ryzyka bezpieczestwa, jeli nie jest zarzdzany ostro偶nie.

- Rozwa偶 Najlepsze Praktyki Bezpieczestwa Kubernetes: Zawsze postpuj zgodnie z najlepszymi praktykami bezpieczestwa Kubernetes, w tym u偶ywajc najmniejszych uprawnie dla dostpu pod贸w do zasob贸w hosta i rozwa偶ajc alternatywne typy wolumin贸w lub mechanizmy (takie jak PVC i PV), kt贸re zapewniaj lepsz izolacj i bezpieczestwo.

Podsumowujc, zachowanie, kt贸re obserwujesz z hostPath i SELinux, jest zamierzone i czy jest odpowiednie, zale偶y od konkretnych wymaga bezpieczestwa i rodowiska. Jest kluczowe, aby zrozumie implikacje i odpowiednio zarzdza powizanymi ryzykami.

**Pytanie:** Czy wiesz, czy i jak mog wyczy relabeling kontekstu SELinux na woluminach (local-storage) dla uprzywilejowanego kontenera? W Podman to `--security-opt label:disable`, ale nie wiem, jak zrobi to samo na k8s (u偶ywam k3s).

**Odpowied藕:** W Kubernetes, szczeg贸lnie przy u偶yciu dystrybucji takich jak k3s, bezporednia kontrola nad relabeling kontekstu SELinux na poziomie rodowiska uruchomieniowego kontenera (podobnie jak mo偶na to zrobi z `--security-opt label:disable` Podmana) nie jest udostpniana przez standardowe specyfikacje Pod Kubernetes. Jest to dlatego, 偶e Kubernetes abstrahuje wiele szczeg贸贸w specyficznych dla rodowiska uruchomieniowego kontenera, aby zapewni przenono i sp贸jno w r贸偶nych rodowiskach i rodowiskach uruchomieniowych kontener贸w, jednak istnieje kilka podej, kt贸re mo偶esz rozwa偶y, aby osign podobny efekt w rodowisku Kubernetes (lub k3s), szczeg贸lnie przy u偶yciu lokalnego storage i uprzywilejowanych kontener贸w.

1. Korzystanie z kontekstu bezpieczestwa w specyfikacjach Pod
Chocia偶 Kubernetes bezporednio nie oferuje opcji wyczenia przepisywania kontekstu SELinux dla wolumin贸w, mo偶esz okreli pewne konteksty bezpieczestwa na poziomie poda lub kontenera. Dla uprzywilejowanego kontenera, twoja specyfikacja poda mo偶e zawiera securityContext wygldajcy mniej wicej tak:

```yaml
Copy code
apiVersion: v1
kind: Pod
metadata:
  name: my-privileged-pod
spec:
  containers:
  - name: my-container
    image: myimage
    securityContext:
      privileged: true
  securityContext:
    seLinuxOptions:
      type: spc_t
```

Typ SELinux `spc_t` jest u偶ywany przez super uprzywilejowane kontenery i mo偶e zapewni poziom dostpu, kt贸rego szukasz, chocia偶 to nie to samo co cakowite wyczenie etykietowania SELinux. Zasadniczo pozwala to kontenerowi dziaa z prawie 偶adnymi ograniczeniami SELinux, ale podejcie to wymaga, aby tw贸j system i polityki SELinux wspieray typ `spc_t`.

2. Modyfikowanie polityk SELinux na hocie

Poniewa偶 Kubernetes i k3s nie udostpniaj sposobu na bezporednie wyczenie przepisywania SELinux dla wolumin贸w, innym podejciem jest zarzdzanie politykami SELinux na systemie hosta, aby umo偶liwi potrzebne wzorce dostpu bez przepisywania. Obejmuje to:

    - Identyfikacj kontekst贸w SELinux u偶ywanych przez twoje kontenery k3s i lokalne woluminy storage.
    - Tworzenie niestandardowych polityk SELinux, kt贸re pozwalaj na wymagany dostp midzy tymi kontekstami.

Podejcie to wymaga dobrej znajomoci zarzdzania politykami SELinux i mo偶e obejmowa narzdzia takie jak audit2allow do generowania niestandardowych modu贸w polityki na podstawie log贸w audytowych zablokowanych operacji.

3. Ostro偶ne korzystanie z hostPath

Jak zauwa偶yem z hostPath, nie wykonuje on przepisywania SELinux, co mo偶e su偶y twoim potrzebom w niekt贸rych przypadkach. Jednak偶e, korzystanie z hostPath wymaga ostro偶nej oceny ze wzgldu na implikacje bezpieczestwa zwizane z udostpnianiem system贸w plik贸w hosta podom.

##### Ograniczenia i rozwa偶ania

- **Implikacje bezpieczestwa**: Uruchamianie kontener贸w w trybie uprzywilejowanym i zmienianie polityk SELinux mo偶e mie znaczce implikacje dla bezpieczestwa. Istotne jest zrozumienie ryzyka i stosowanie takich konfiguracji tylko wtedy, gdy s absolutnie konieczne, zgodnie z zasad najmniejszych uprawnie.

- **Kompatybilno i wsparcie**: Wszelkie modyfikacje polityk SELinux lub kontekst贸w bezpieczestwa Kubernetes powinny by dokadnie testowane, aby upewni si, 偶e nie zak贸caj niezamierzenie innych aspekt贸w dziaania lub bezpieczestwa twojego klastra.

##### Wnioski

Chocia偶 Kubernetes nie oferuje bezporedniego odpowiednika dla opcji Podman --security-opt label:disable, przez staranne zarzdzanie kontekstami bezpieczestwa pod贸w i politykami SELinux na hocie, mo偶esz osign podobne wyniki. Zawsze r贸wnowa偶 wymagania operacyjne z najlepszymi praktykami bezpieczestwa, aby utrzyma integralno i bezpieczestwo twojego klastra.

**Pytanie:** Jak dokadnie hostPath r贸偶ni si technicznie od lokalnego woluminu storage oraz jak r贸偶ni si w kontekcie SELinux, o kt贸rym wczeniej rozmawialimy?

**Odpowied藕:** R贸偶nice midzy woluminami hostPath a lokalnymi woluminami storage w Kubernetes, szczeg贸lnie w kontekcie SELinux, dotycz zar贸wno ich przeznaczonych zastosowa, jak i sposobu interakcji z zasadami bezpieczestwa systemu bazowego. Oto gbsze spojrzenie na techniczne r贸偶nice:

##### Woluminy hostPath

- **Dostp bezporedni**: Woluminy hostPath zapewniaj bezporedni dostp do systemu plik贸w wza, na kt贸rym dziaa pod. Kiedy okrelasz wolumin hostPath, w zasadzie m贸wisz Kubernetes, aby zamontowa okrelony plik lub katalog z hosta do poda. Pomija to bardziej zarzdzane i abstrakcyjne procesy dostarczania storage Kubernetes.

- **Kontekst SELinux**: Przy u偶yciu hostPath, kontekst SELinux plik贸w lub katalog贸w, do kt贸rych jest dostp, jest okrelony przez ich istniejce etykiety w systemie plik贸w hosta. Kubernetes nie wykonuje 偶adnego automatycznego przepisywania kontekstu SELinux dla wolumin贸w hostPath. Oznacza to, 偶e pod musi mie odpowiedni kontekst SELinux, aby interakcjonowa z danymi tak, jak istniej na hocie, lub operacja musi by dozwolona przez obecn polityk SELinux. To zachowanie mo偶e prowadzi do odm贸w dostpu, jeli kontekst SELinux poda nie pozwala na interakcj z kontekstem SELinux hostPath.

##### Lokalne woluminy storage

- **Dynamiczne dostarczanie**: Lokalne woluminy trwae (LPV) maj na celu zapewnienie bardziej trwaego i przenonego sposobu korzystania z lokalnego storage w Kubernetes. W przeciwiestwie do hostPath, kt贸ry bezporednio okrela cie偶k na hocie, lokalne woluminy s dostarczane i zarzdzane przez mechanizmy Wolumin Trway (PV) i Wnioski o Wolumin Trway (PVC). Pozwala to na dynamiczne dostarczanie i bardziej szczeg贸ow kontrol nad waciwociami storage, w tym pojemnoci, trybami dostpu i, do pewnego stopnia, ustawieniami bezpieczestwa.

- **Przepisywanie kontekstu SELinux**: Dla dynamicznie dostarczanych wolumin贸w, w tym tych dostarczanych jako lokalne przechowywanie przez PV, Kubernetes wspiera automatyczne przepisywanie kontekstu SELinux na podstawie kontekstu SELinux poda. To przepisywanie zapewnia, 偶e zamontowany wolumin jest dostpny dla poda pod egid SELinux, dopasowujc etykiet SELinux woluminu do wymaga bezpieczestwa poda. To automatyczne przepisywanie jest czci podejcia Kubernetes do obsugi bezpieczestwa wolumin贸w w dynamicznym, wielodostpnym rodowisku.

##### Kluczowe r贸偶nice w kontekcie SELinux

- **Automatyczne przepisywanie**: Najwiksza r贸偶nica pod spodem, w kontekcie SELinux, polega na tym, 偶e woluminy hostPath nie przechodz automatycznego przepisywania kontekstu SELinux, podczas gdy lokalne woluminy storage dostarczane przez mechanizm PV/PVC mog by automatycznie przepisane, aby dopasowa si do kontekstu SELinux poda. Ta r贸偶nica jest kluczowa dla bezpieczestwa i kontroli dostpu w rodowiskach z egzekwowanym SELinux.

- **U偶ycie i elastyczno vs. Bezpieczestwo**: hostPath jest bardziej elastyczny, ale mniej bezpieczny, poniewa偶 pozwala podom na bezporedni dostp i potencjaln modyfikacj system贸w plik贸w hosta bez porednictwa abstrakcji storage Kubernetes. Lokalne woluminy storage s zaprojektowane tak, aby integrowa si z modelami storage i bezpieczestwa Kubernetes, zapewniajc r贸wnowag midzy wykorzystaniem lokalnych zasob贸w dyskowych a utrzymaniem bezpieczestwa i przenonoci.

##### Podsumowanie

Wyb贸r midzy woluminami `hostPath` a lokalnymi w Kubernetes powinien by podyktowany konkretnymi wymaganiami aplikacji oraz postaw bezpieczestwa w rodowisku. `hostPath` oferuje bezporedni, niemediowany dostp do system贸w plik贸w hosta, odpowiedni dla konkretnych przypadk贸w, gdzie taki dostp jest absolutnie niezbdny. W przeciwiestwie, lokalne woluminy dyskowe zapewniaj bardziej zarzdzany, bezpieczny spos贸b na wykorzystanie lokalnych zasob贸w dyskowych, zgodny z dynamicznym przydzielaniem Kubernetes i mechanizmami kontroli dostpu, w tym egzekwowaniem polityki SELinux i ponownym etykietowaniem.

Tak, twoje rozumienie jest poprawne. Rozmowa o woluminach `hostPath`, kontekcie SELinux i ich interakcji jest rzeczywicie kluczowa, zwaszcza w rodowiskach, gdzie SELinux jest wczony i egzekwowany. Pozw贸l, 偶e podsumuj i rozwin, jak to ma zastosowanie do twojego scenariusza z AWX dziaajcym na Kubernetes, oraz szerszych implikacji u偶ycia `hostPath` dla wolumin贸w w takich kontekstach.

### SELinux i Woluminy Kubernetes:

- **Konteksty SELinux**: SELinux u偶ywa kontekst贸w do egzekwowania polityk bezpieczestwa na plikach i procesach. Kontekst procesu okrela jego uprawnienia do interakcji z plikami lub innymi procesami. W rodowisku Kubernetes, te konteksty r贸wnie偶 maj zastosowanie do kontener贸w i wolumin贸w, z kt贸rych korzystaj.

- **Woluminy hostPath**: Kiedy u偶ywasz woluminu `hostPath` w Kubernetes, wolumin jest montowany bezporednio do poda z systemu plik贸w hosta bez zmiany jego kontekstu SELinux. Oznacza to, 偶e dla poda, aby uzyska dostp do woluminu `hostPath`, polityka SELinux musi pozwoli kontekstowi SELinux kontenera na interakcj z kontekstem systemu plik贸w hosta, gdzie `hostPath` wskazuje.

### Interakcja z SELinux:

- **Bezporedni Dostp z hostPath**: Bezporedni dostp zapewniany przez `hostPath` mo偶e by mieczem obosiecznym. Jest korzystny dla przypadk贸w u偶ycia, gdzie okrelone pliki lub katalogi na hocie musz by dostpne dla poda. Jednak偶e, mo偶e to wprowadzi ryzyko bezpieczestwa, jeli nie jest starannie zarzdzane, szczeg贸lnie w rodowiskach z egzekwowanym SELinux, poniewa偶 omija warstw abstrakcji Kubernetes zaprojektowan do bardziej bezpiecznego zarzdzania kontrolami dostpu i alokacj zasob贸w.

- **Dlaczego Dostp Dziaa w Niekt贸rych Przypadkach**: W rodowiskach, gdzie SELinux jest ustawiony na tryb permisywny lub gdzie polityki s skonfigurowane do zezwalania na specyficzne wzorce dostpu wymagane przez twoje pody Kubernetes, mo偶esz nie napotka odm贸w dostpu. Ta elastyczna dostpno nie jest wad SELinux, ale raczej wskazaniem, 偶e polityki SELinux s poprawnie skonfigurowane, aby pozwoli na niezbdne interakcje midzy twoimi podami a systemem hosta.

- **Problem z Odmow Dostpu**: Problem "Odmowa Dostpu" pojawia si, gdy kontekst SELinux katalogu lub pliku na hocie nie pozwala na dostp przez kontekst SELinux, w kt贸rym dziaa kontener. Nawet jeli kontener dziaa jako u偶ytkownik z UID 0 (root), polityki SELinux mog nadal ogranicza dostp na podstawie kontekst贸w.

### Rozwa偶ania dotyczce Bezpieczestwa i Najlepsze Praktyki:

- **Minimalizacja Ryzyka**: Aby zminimalizowa ryzyko bezpieczestwa, zaleca si u偶ywanie wolumin贸w zarzdzanych przez Kubernetes (takich jak PVC), kt贸re s zaprojektowane do bezproblemowej pracy z modelem bezpieczestwa Kubernetes, w tym wsparcia dla automatycznego ponownego etykietowania kontekstu SELinux w razie potrzeby.

- **Polityki SELinux**: Jeli musisz u偶ywa `hostPath`, upewnij si, 偶e polityki SELinux na hocie s starannie opracowane, aby zezwoli tylko na niezbdny dostp przez pody Kubernetes, nie otwierajc szerszych uprawnie, kt贸re mogyby zosta wykorzystane.

- **Bezpieczestwo Kontener贸w**: Fakt, 偶e kontenery dziaaj z ograniczonymi uprawnieniami i bez penego systemu init jak systemd, jest czci modelu bezpieczestwa kontener贸w. Kontenery maj na celu by lekkie i uruchamia pojedyncz aplikacj lub proces w bezpieczny i izolowany spos贸b. Uzyskanie dostpu roota w kontenerze lub uruchamianie systemd w kontenerze jest sprzeczne z tymi praktykami bezpieczestwa i jest og贸lnie odradzane.

Podsumowujc, pracujc w rodowiskach z wczonym SELinux, zrozumienie interakcji midzy kontekstami SELinux a woluminami Kubernetes jest kluczowe dla utrzymania bezpieczestwa przy zapewnieniu niezbdnego dostpu dla twoich aplikacji. Konfigurowanie polityk SELinux i kontekst贸w bezpieczestwa Kubernetes w odpowiedni spos贸b mo偶e pom贸c osign po偶dan funkcjonalno bez kompromisu w zakresie bezpieczestwa.

### Podsumowanie:

Podsumujmy problem.

1. **Problem z katalogiem projekt贸w AWX**: Zauwa偶yem, 偶e utworzenie projektu w AWX nie byo mo偶liwe, poniewa偶 katalog projektu nie istnia w w藕le sieciowym AWX. Jako obejcie rozwa偶yem rczne utworzenie katalogu projektu, uzyskujc dostp do wza za pomoc `kubectl exec`.

2. **Trwae rozwizanie z wykorzystaniem Wolumen贸w Trwaych (PV) i Wniosk贸w o Wolumen Trway (PVC)**: Uznajc, 偶e zmiany manualne zostan utracone, jeli wze zostanie usunity, zbadaem bardziej trwae rozwizanie polegajce na modyfikacji istniejcej ksi偶ki playbook ansible. Rozwizanie to polegao na utworzeniu zasob贸w PV i PVC, aby zapewni, 偶e katalog projektu AWX przetrwa restarty i usunicia wz贸w.

3. **Modyfikacje ksi偶ki playbook ansible**: Celem byo dodanie zada do ksi偶ki playbook ansible, aby utworzy zasoby PV i PVC. Dodatkowo, chciaem zmodyfikowa plik `awx.yaml` w ksi偶ce playbook, aby zawiera `projects_persistence: true` oraz `projects_existing_claim: awx-projects-claim`, zapewniajc, 偶e AWX u偶yje PVC do storage projekt贸w.

4. **SELinux i wolumeny `hostPath`**: Dyskusja dotkna r贸wnie偶 sposobu dziaania wolumen贸w `hostPath` z SELinux, podkrelajc znaczenie kontekst贸w i uprawnie SELinux przy u偶ywaniu wolumen贸w `hostPath` w Kubernetes. Zwr贸cono uwag, 偶e wolumeny `hostPath` nie wyzwalaj automatycznie zmiany etykiety kontekstu SELinux, co mo偶e prowadzi do problem贸w z uprawnieniami, chyba 偶e polityki SELinux s odpowiednio skonfigurowane.

5. **Ostateczne rozwizanie ksi偶ki playbook ansible**: Udostpniem ostateczn wersj mojej ksi偶ki playbook ansible zaprojektowan do instalowania i usuwania AWX oraz jego zasob贸w z Kubernetes. Ta ksi偶ka playbook do usuwania AWX zawiera kroki do usuwania konkretnych wdro偶e, kont serwisowych, powiza r贸l, r贸l i skalowania w d贸 wdro偶e przed usuniciem PVC, PV i ostatecznie przestrzeni nazw. Ksi偶ka playbook wykorzystuje `ignore_errors: yes`, aby zapewni kontynuacj wykonania ksi偶ki playbook nawet jeli niekt贸re zasoby s ju偶 usunite lub nie znalezione.

7. **Podsumowanie**: Dyskusja dostarczya wgld贸w w zarzdzanie zasobami Kubernetes za pomoc ansible, szczeg贸lnie dla utrzymania trwaego storage z wdro偶eniami AWX oraz obsugi zasob贸w Kubernetes w spos贸b, kt贸ry respektuje polityki SELinux. Ostateczna ksi偶ka playbook udostpniona przez Ciebie oferuje kompleksowe podejcie do czystego usuwania AWX i jego zasob贸w z klastra Kubernetes, podkrelajc staranne zarzdzanie zasobami i praktyki sprztania.

殴r贸da:
* [AWX](https://github.com/ansible/awx)
* [Operator AWX](https://github.com/ansible/awx-operator)
* [Dokumentacja instalacji operatora AWX](https://ansible.readthedocs.io/projects/awx-operator/en/latest/installation/basic-install.html)
* [Binarki Kustomize](https://kubectl.docs.kubernetes.io/installation/kustomize/binaries/)
* [Wydania i tagi AWX](https://github.com/ansible/awx-operator/releases)
