---
title: Kontroler ingress NGINX dla n8n - jak go stworzy i wdro偶y w Kubernetes
date: 2024-01-12T21:00:00+00:00
description: Artyku wyjania, czym jest kontroler ingress NGINX w Kubernetes i jak go stworzy dla n8n oraz wdro偶y. Opisuje r贸wnie偶 bd 404 kontrolera ingress NGINX i pokazuje, jak rozwiza ten problem.
draft: false
hideToc: false
enableToc: true
enableTocContent: false
author: sysadmin
authorEmoji: 
pinned: false
asciinema: true
series:
- Kubernetes
categories:
- Raspberry Pi
cover:
    image: images/2024-thumbs/nginx-ingress-controller-n8n.webp
---
**Oto kr贸tki film; czytaj dalej, aby dowiedzie si wicej.**
{{<youtube wMaaoJ9Oj8M>}}

  Zalecam obejrzenie caego filmu, aby zrozumie, jak wszystko zostao zrobione i wdro偶one.

W poprzednim samouczku [Jak wdro偶y n8n w Kubernetes - k3s](/en/blog/how-to-deploy-n8n-in-kubernetes-k3s/) wdro偶yem n8n.

Sprawdziem, 偶e wszystko dziaa poprawnie.

```bash
kubectl get all -n n8n
NAME                                  READY   STATUS    RESTARTS   AGE
pod/postgres-statefulset-0            1/1     Running   0          23h
pod/n8n-deployment-6dfd7cc794-pgccd   1/1     Running   0          23h

NAME                       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
service/postgres-service   ClusterIP   None           <none>        5432/TCP       23h
service/n8n-service        NodePort    10.43.216.21   <none>        80:32469/TCP   23h

NAME                             READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/n8n-deployment   1/1     1            1           23h

NAME                                        DESIRED   CURRENT   READY   AGE
replicaset.apps/n8n-deployment-6dfd7cc794   1         1         1       23h

NAME                                    READY   AGE
statefulset.apps/postgres-statefulset   1/1     23h
```

Jedna osoba (ona lub on) zostawia komentarz pod moim kr贸tkim filmem {{<youtube FW8TP5UDq4g>}}

> Wdro偶yem moje klastry k8s na metalu i wdro偶yem kontroler wejcia nginx w klastrze, problem, z kt贸rym si borykam, to taki, 偶e domena, kt贸r wskazaem na wze g贸wny, gdy u偶ywam curl na domenie, otrzymuj po偶dany wynik, ale w przegldarce mam 404, czy masz jaki pomys, jak mog rozwiza ten problem?
>
> <cite>@user-ph7sl6mn5q  </cite>

Zdecydowaem wyjani, jak dziaa kontroler wejcia NGINX, u偶ywajc przykadu wdro偶enia dla aplikacji n8n i co wa偶niejsze, odtworzy bd 404 kontrolera wejcia NGINX.

Przedstawiem, 偶e opr贸cz kontrolera wejcia potrzebna jest dodatkowa usuga. Mo偶esz zapyta: - Dlaczego potrzebuj drugiej usugi, aby to dziaao?

Poni偶ej znajduj si wszystkie pliki potrzebne do kontrolera wejcia nginx dla n8n znajdujce si w katalogu ingress, kt贸re mo偶esz pobra za pomoc repozytorium: [n8n-k3s](https://github.com/sysadmin-info/n8n-k3s.git)

```bash
cat ingress-n8n-class.yml
```

```yaml
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  name: nginx
spec:
  controller: k8s.io/ingress-nginx
```

```bash
cat n8n-ingress.yml
```

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: n8n-ingress
  namespace: n8n
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: n8n-service
            port:
              number: 80
```

```bash
cat nginx-ingress-n8n-service.yml
```

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-ingress-n8n
  namespace: ingress-nginx
spec:
  type: NodePort
  ports:
    - port: 80
      nodePort: 5678
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: ingress-nginx
```

Poniewa偶 wdra偶am n8n wraz z kontrolerem wejcia NGINX, zamieszanie wydaje si dotyczy koniecznoci posiadania dw贸ch r贸偶nych usug: n8n-service i nginx-ingress-n8n-service. Wyjanijmy ich role i dlaczego obie s potrzebne.

1. **n8n-service (NodePort Service)**: Ta usuga jest odpowiedzialna za udostpnianie wewntrznych aplikacji n8n w klastrze Kubernetes. Dziaa jako wewntrzny balanser obci偶enia, kt贸ry kieruje ruch do twoich pod贸w n8n. Jako usuga NodePort umo偶liwia r贸wnie偶 dostp do aplikacji z zewntrz klastra, ale przez okrelony port na wzach.

2. **nginx-ingress-n8n-service (NodePort Service dla Ingress)**: Ta usuga jest powizana z kontrolerem wejcia NGINX. Jej g贸wna rola polega na udostpnieniu samego kontrolera wejcia na zewntrz. To jest inne ni偶 `n8n-service`, poniewa偶 nie udostpnia bezporednio twojej aplikacji. Zamiast tego udostpnia kontroler wejcia, kt贸ry nastpnie zarzdza i kieruje zewntrzny ruch do twoich wewntrznych usug (takich jak `n8n-service`) na podstawie zdefiniowanych przez ciebie zasad wejcia.

Oto dlaczego obie s potrzebne:

- `n8n-service` umo偶liwia dostp do twojej aplikacji n8n wewntrz klastra Kubernetes i potencjalnie bezporednio z zewntrz klastra (cho to ostatnie zwykle nie jest zalecane w rodowiskach produkcyjnych).
  
- `nginx-ingress-n8n-service` udostpnia kontroler wejcia NGINX. Gdy zewntrzny ruch trafia na t usug, to kontroler wejcia decyduje, dokd skierowa ten ruch na podstawie twoich zasad wejcia (`n8n-ingress.yml`). W tym przypadku kieruje ruch do `n8n-service`.

Podsumowujc, `n8n-service` su偶y do wewntrznego balansowania obci偶enia i potencjalnego bezporedniego zewntrznego dostpu do n8n, podczas gdy `nginx-ingress-n8n-service` su偶y do zewntrznego dostpu do kontrolera wejcia, kt贸ry nastpnie inteligentnie kieruje ruch do wewntrznych usug, takich jak `n8n-service`. To oddzielenie umo偶liwia bardziej wyrafinowane zasady routingu, lepsze bezpieczestwo i atwiejsze zarzdzanie ruchem wejciowym w rodowisku Kubernetes.

{{< notice success "Wa偶na informacja" >}}
Kontroler NGINX ingress dla konkretnej usugi musi zosta utworzony w tej samej przestrzeni nazw, w kt贸rej usuga jest uruchomiona.
{{< /notice >}}

Ale to nie wszystko, co musisz wiedzie, aby zrozumie, jak to dziaa.

Poni偶szy wpis pokazuje regu iptables:

```bash
sudo iptables -t nat -L PREROUTING --line-numbers -n -v
Chain PREROUTING (polityka ACCEPT 326 pakiet贸w, 43216 bajt贸w)
num   pkts bytes target     prot opt in     out     source               destination         
1    17677 2468K KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* portale usug kubernetes */
```

Musisz r贸wnie偶 zmodyfikowa usug k3s, aby zmieni zakres port贸w w spos贸b, kt贸ry przedstawiem. Bez tego nie zadziaa, poniewa偶 u偶ywam NodePort 5678, a domylnie Kubernetes u偶ywa zakresu port贸w od 30000 do 32767.

Wic edytuj plik k3s.service

```bash
sudo vim /etc/systemd/system/k3s.service
```

i dodaj wpis w spos贸b, jaki mo偶esz zobaczy na filmie.

```vim
'--service-node-port-range=5678-32767'
```

Nastpnie przeaduj daemona i zrestartuj usug k3s.

```bash
sudo systemctl daemon-reload
sudo systemctl restart k3s.service
```

{{< notice success "Wa偶na informacja" >}}
Restart usugi Kubernetes ( w tym przypadku K3S) nie powoduje zmiany NodePort dla usug, kt贸rych deployment nastpi wczeniej i dziaaya, poniewa偶 raz przypisany losowo przez Kubernetes NodePort ulega zmianie dopiero w momencie usunicia usugi.
{{< /notice >}}

Dodatkowo IngressClass zosta dodany przez ingress-class.yml i jest r贸wnie偶 okrelony w pliku n8n-ingresss.yml.

Przeanalizujmy komponenty i ich role w zarzdzaniu ruchem sieciowym dla mojego ustawienia Kubernetes, koncentrujc si na iptables, kontrolerze Ingress i zakresie port贸w usugi node.

1. **Wpis Iptables dla usug Kubernetes**: Wpis iptables, kt贸ry pokazae (`KUBE-SERVICES`), jest czci mechanizmu, kt贸rego Kubernetes u偶ywa do zarzdzania ruchem sieciowym do usug. Ta regua jest generowana automatycznie przez Kubernetes i odpowiada za kierowanie ruchem do odpowiednich usug w klastrze na podstawie ich typu i konfiguracji.

2. **Zakres port贸w usugi Node (`--service-node-port-range=5678-32767`)**: Ta modyfikacja konfiguracji `k3s.service` rozszerza zakres port贸w, kt贸re mog by u偶ywane dla usug NodePort. Domylnie usugi NodePort w Kubernetes s przydzielane portom z zakresu 30000-32767. Twoja modyfikacja pozwala usugom u偶ywa port贸w zaczynajc od 5678, co obejmuje konkretny port, kt贸ry skonfigurowae dla twojej usugi Ingress NGINX (`nginx-ingress-n8n-service`).

3. **Ingress i IngressClass**: Twoje pliki `n8n-ingress.yml` i `ingress-n8n-class.yml` definiuj zas贸b Ingress i IngressClass, odpowiednio. IngressClass (`nginx`) informuje Kubernetes, kt贸ry kontroler Ingress powinien obsugiwa zasoby Ingress. Ingress (`n8n-ingress`) definiuje, jak ruch powinien by kierowany do twoich usug (takich jak `n8n-service`).

4. **Przepyw ruchu**:
    - Zewntrzny ruch dociera do wza Kubernetes na konkretnym porcie (zdefiniowanym przez twoj usug NodePort, `nginx-ingress-n8n-service`).
    - Regua iptables (`KUBE-SERVICES`) kieruje ten ruch do kontrolera Ingress NGINX, na podstawie mapowania NodePort.
    - Kontroler Ingress NGINX, na podstawie regu Ingress (`n8n-ingress`), kieruje ruch do odpowiedniej usugi wewntrz klastra (w twoim przypadku `n8n-service`).

Regua iptables jest rzeczywicie wystarczajca, aby upewni si, 偶e ruch docierajcy do wza Kubernetes na okrelonym NodePort jest prawidowo przekierowywany do kontrolera Ingress NGINX. Stamtd kontroler Ingress przejmuje kontrol nad kier

owaniem ruchu zgodnie z zdefiniowanymi przez ciebie reguami Ingress. Ta konfiguracja zapewnia elastyczny i wydajny spos贸b zarzdzania trasowaniem ruchu w twoim rodowisku Kubernetes.

##### Jak to wdro偶y?

```bash
git clone https://github.com/sysadmin-info/n8n-k3s.git
cd n8n-k3s/ingress
kubectl apply -f ingress-n8n-class.yml -f n8n-ingress.yml -f nginx-ingress-n8n-service.yml
```

##### Jak u偶ywa domeny zamiast adresu IP?

{{< notice success "Uwaga!" >}}
W wideo pokazuj Adguard Home, kt贸ry dziaa jako DNS na porcie 53 oraz NGINX Proxy Manager, aby pokaza, w jaki spos贸b mo偶na przypisa konkretn domen do konkretnego adresu IP (Adguard Home) oraz NodePort (NGINX Proxy Manage).
{{< /notice >}}

Aby u偶ywa nazwy domeny zamiast adresu IP do dostpu do twoich usug Kubernetes (jak n8n w twoim przypadku), zazwyczaj wykonujesz nastpujce kroki:

1. **Zarejestruj nazw domeny**: Jeli jeszcze jej nie masz, musisz zarejestrowa nazw domeny u rejestratora domen. Wybierz nazw, kt贸ra odpowiada twojej usudze lub organizacji.

2. **Skonfiguruj rekordy DNS**: Po uzyskaniu nazwy domeny musisz skonfigurowa jej ustawienia DNS. Obejmuje to tworzenie rekord贸w DNS, kt贸re wskazuj na adres IP twojego klastra Kubernetes (lub konkretnego wza, jeli u偶ywasz usug NodePort).

   - **Rekord A**: Utw贸rz rekord A w konfiguracji DNS, kt贸ry wskazuje twoj domen (np. `example.com`) na zewntrzny adres IP twojego klastra Kubernetes. Jeli tw贸j klaster znajduje si na platformie chmurowej, byby to zewntrzny adres IP twojego Load Balancera. Jeli jest to instalacja lokalna lub na miejscu, byby to zewntrzny adres IP twojego wza.
   - **Rekord CNAME (opcjonalnie)**: Jeli chcesz u偶y subdomeny (takiej jak `n8n.example.com`), mo偶esz utworzy rekord CNAME, kt贸ry wskazuje na twoj g贸wn domen.

3. **Skonfiguruj Ingress, aby u偶ywa domeny**: W twoim zasobie Kubernetes Ingress (`n8n-ingress.yml`) musisz okreli pole host, aby u偶ywa nazwy twojej domeny. Oto przykadowa modyfikacja:

   ```yaml
   apiVersion: networking.k8s.io/v1
   kind: Ingress
   metadata:
     name: n8n-ingress
     namespace: n8n
     annotations:
       nginx.ingress.kubernetes.io/rewrite-target: /
   spec:
     ingressClassName: nginx
     rules:
     - host: n8n.example.com
       http:
         paths:
         - path: /
           pathType: Prefix
           backend:
             service:
               name: n8n-service
               port:
                 number: 80
   ```

W tym przykadzie zastp `n8n.example.com` swoj rzeczywist nazw domeny.

4. **Przeaduj lub zastosuj ponownie Ingress**: Po zmodyfikowaniu zasobu Ingress zastosuj zmiany za pomoc `kubectl apply -f n8n-ingress.yml`. Kontroler Ingress NGINX powinien zaapa te zmiany i zacz kierowa ruch na podstawie nazwy domeny.

5. **Przetestuj nazw domeny**: Po ustawieniu wszystkiego mo偶esz przetestowa dostp do twojej usugi za pomoc nazwy domeny (np. `http://n8n.example.com`). Powinno to kierowa do twojej usugi n8n tak samo jak wczeniej metoda IP i port.

Pamitaj, 偶e zmiany w DNS mog zaj troch czasu, aby rozprzestrzeni si w internecie, wic mo偶e to nie dziaa od razu. Upewnij si r贸wnie偶, 偶e konfiguracja sieciowa twojego klastra Kubernetes pozwala na przychodzcy ruch na odpowiednich portach (takich jak 80 lub 443 dla HTTP/HTTPS).

##### Jak odtworzyem bd 404 dla kontrolera Ingress NGINX?

Translation:

Zrobiem celowo bd w pliku n8n-ingress.yml, aby pokaza, 偶e ma on problem z syntaxem w sekcji rules. To mo偶e by powodem, dla kt贸rego Tw贸j Ingress nie kieruje ruchu poprawnie do twojej usugi n8n. Klucze host i http powinny by czci tej samej reguy, ale obecnie s oddzielone, co sprawia, 偶e konfiguracja Ingress jest nieprawidowa.

Poni偶ej znajduje si plik yaml z bdem:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: n8n-ingress
  namespace: n8n
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: n8n.example.com
    - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: n8n-service
            port:
              number: 80

```

A tu masz poprawny plik. R贸偶nica jest prosta. Usunem symbol - dla http:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: n8n-ingress
  namespace: n8n
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: n8n.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: n8n-service
            port:
              number: 80
```

W tej poprawionej wersji klucz `host` jest teraz poprawnie powizany z kluczem `http` w ramach tej samej reguy. Ta zmiana powinna pozwoli Ingress na poprawne kierowanie ruchu dla `n8n.sysadmin.homes` do usugi `n8n-service` na porcie 80.

Po dokonaniu tej zmiany zastosuj konfiguracj u偶ywajc:

```bash
kubectl apply -f n8n-ingress.yml
```

Nastpnie przetestuj dostp do `n8n.sysadmin.homes` ponownie. To powinno rozwiza problem z komunikatem 404 Not Found, zakadajc, 偶e wszystkie inne elementy twojej konfiguracji (jak DNS i konfiguracja usugi) s poprawne.